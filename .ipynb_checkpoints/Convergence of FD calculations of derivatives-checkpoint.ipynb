{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Convergence of explicit finite difference formulations demonstrated on derivatives"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# change to working directory and configure autoreloading of modules, resize output windows, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.auto_scroll_threshold = 9999;"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'Convergence of FD calculations of derivatives'\n",
      "/home/dsirajud/Work/IPython-notebooks/Convergence of FD calculations of derivatives/pyfiles/bin\n"
     ]
    }
   ],
   "source": [
    "cd Convergence\\ of\\ FD\\ calculations\\ of\\ derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'pyfiles/'\n",
      "/home/dsirajud/Work/IPython-notebooks/Convergence of FD calculations of derivatives/pyfiles/bin\n"
     ]
    }
   ],
   "source": [
    "cd pyfiles/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'bin'\n",
      "/home/dsirajud/Work/IPython-notebooks/Convergence of FD calculations of derivatives/pyfiles/bin\n"
     ]
    }
   ],
   "source": [
    "cd bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the infinitely differentiable function:\n",
    "\n",
    "$$f(x) = \\sin(\\pi x) + 1 $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which have derivatives ($n\\in\\mathbb{N}_1$) :\n",
    "\n",
    "$$f^{(2n-1)}(x) = (-1)^{n+1} \\pi^{2n - 1} \\cos(\\pi x)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$f^{(2n)}(x) = (-1)^n \\pi^{2n}\\sin(\\pi x)$$\n",
    "\n",
    "Below, we plot the function as well as four normalized derivatives, the normalized derivatives of higher order are coincident with those plotted. Note, this is only to fit them on the same plot, for convergence we properly analyze the unnormalized forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD9CAYAAACrxZCnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+yIVQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x341b190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload \n",
    "%autoreload 2 \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-1,1,1000)\n",
    "f =  np.sin(np.pi*x) + 1\n",
    "nmax = 4 # maximum derivative desired to be plotted\n",
    "\n",
    "fig, ax = plt.figure(), plt.subplot(111)\n",
    "\n",
    "ax.plot(x,f, linewidth = 2, label = '$f(x)$')\n",
    "ax.hold('on')\n",
    "\n",
    "for n in range(1,nmax + 1):\n",
    "    if np.mod(n,2) == 1: # n is odd\n",
    "        dnf = (-1) ** (n + 1) * np.pi ** (2*n - 1) * np.cos(np.pi * x)\n",
    "        dnf /= np.pi ** (2*n - 1) # i.e. we plot normalized derivatives\n",
    "\n",
    "    else: # n is even\n",
    "        dnf = (-1) ** n * np.pi ** (2*n) * np.sin(np.pi * x)\n",
    "        dnf /= np.pi ** (2*n) # i.e. we plot normalized derivatives\n",
    "\n",
    "    ax.plot(x,dnf, linewidth = 2, linestyle = '--', label = r'$\\pi^{-%i}\\partial_x^{%i} f$' % (n,n) )\n",
    "\n",
    "ax.hold('off')\n",
    "frame = ax.get_position() # position of plot center\n",
    "\n",
    "# shrink frame of the plot to make room for a legend on the right side\n",
    "ax.set_position([frame.x0, frame.y0, \n",
    "                 frame.width * 0.8, frame.height])\n",
    "\n",
    "# Place legend to the right of the shrunken frame\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "          fancybox=True, ncol=1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the script pyfiles/bin/generate_tables_of_finite_difference_schemes_for_a_given_LTE.py to generate tables of explicit finite difference schemes for grids with uniform spacing $\\Delta x$ for a chosen order of derivative and a specified maximum LTE. For example, if we desire an LTE (sys.argv[1]) of 1 and want the family of finite difference schemes corresponding to the second derivative 2 (sys.argv[2]), we run from the terminal "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pyfiles/bin$ python generate_tables_of_finite_difference_schemes_for_a_given_LTE.py 1 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which produces the table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "f^(2): LTE = O(z^1)\n",
    "=========================\n",
    "\n",
    "f^(2): forward 0\n",
    "-------------------------\n",
    "(weights, stencil)\n",
    "1.00000,  0\n",
    "-2.00000,  1\n",
    "1.00000,  2\n",
    "-------------------------\n",
    "f^(2): central 0\n",
    "-------------------------\n",
    "(weights, stencil)\n",
    "1.00000, -1\n",
    "-2.00000,  0\n",
    "1.00000,  1\n",
    "-------------------------\n",
    "f^(2): backward 0\n",
    "-------------------------\n",
    "(weights, stencil)\n",
    "1.00000, -2\n",
    "-2.00000, -1\n",
    "1.00000,  0\n",
    "-------------------------\n",
    "=========================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The weights of which are well-known, the labeling 'forward', 'central', and 'backward' indicate the handedness of the grid sampling for each scheme while the the associated number 0 communicates the degree of asymmetry from those schemes (central always has 0 asymmetry due to its definition). For example, a forward 0 scheme has a stencil that samples grid points strictly forward of point of interest, a forward 1 scheme has a stencil that samples one grid point backward and the rest forward (consider stencils greater than 3 for an instance, e.g. 2nd derivative with LTE = 2 has 2 + 2 = 4 grid points in the stencil for these explicit schemes), and so on. If a non-central scheme is more aptly named according to a different scheme (e.g. the 'forward 1' [and 'backward 1'] above is better known as the central scheme), the namechange is commited in favor of the corresponding asymmetric labeling 'forward/backward 1'. Note, the central scheme is actually second order because the first order term fortuitously cancels, this is also well-known. Thus, the script generates a family of schemes guaranteed to be at least the chosen LTE, though in the event a central scheme exists a serendipitous cancellation of an extra order term in the truncation error occurs raising its LTE order. This fortune, we say from experience, never happens for forward or backward schemes, so the script can be said to generate families of forward/backward schemes of the chosen LTE and the central scheme of at least the chosen LTE, though it may be more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights $\\{w\\}$ and stencil $\\{i\\}$ can be used to calculate the derivative according:\n",
    "\n",
    "\\begin{equation}f^{(n)}(x) = \\tfrac{1}{(\\Delta x)^n}\\sum_i w_i f(x + i\\Delta x)\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases on first derivative with LTE = $O(\\Delta x^3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For example, selecting one scheme in particular: a fully forward differencing scheme ('forward 0') at an LTE of order 3 for the second derivative. The following demonstrates convergence (where we apply the differencing near the edges by periodicity)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pyfiles/bin$ python generate_tables_of_finite_difference_schemes_for_a_given_LTE.py 3 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, we generate the table interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import generate_tables_of_finite_difference_schemes_for_a_given_LTE\n",
    "\n",
    "generate_tables_of_finite_difference_schemes_for_a_given_LTE.main(LTE = 3, dn = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates the table of finite difference coefficients \"f1_LTE_3_FD_coefficients.dat\" which is read and stored by pyfiles/main.py to use the scheme as needed. Running a convergence test for 10 grids where each subsequent grid has twice as many grid points as the previous,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence of a single scheme (edge sampling completed by periodicity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the formulation just above, we run a mesh refinement exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: './etc/f1_LTE_3_FD_coefficients.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-6ac2630ddd71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconvergence_routine_single_scheme\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconvergence_routine_single_scheme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNumGrids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLTE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandedness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'forward'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masymmetry\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mmain.pyc\u001b[0m in \u001b[0;36mconvergence_routine_single_scheme\u001b[1;34m(NumGrids, Nx, LTE, dn, handedness, asymmetry)\u001b[0m\n",
      "\u001b[1;32mmain.pyc\u001b[0m in \u001b[0;36mFD_derivative_one_scheme_periodic\u001b[1;34m(handedness, asymmetry, dn, LTE, Nx)\u001b[0m\n",
      "\u001b[1;32m/home/dsirajud/Work/IPython-notebooks/Convergence of FD calculations of derivatives/pyfiles/../pyfiles/lib/make_FD_schemes_dict.pyc\u001b[0m in \u001b[0;36mstore\u001b[1;34m(dn, LTE)\u001b[0m\n\u001b[0;32m     20\u001b[0m                       \u001b[0minfilepath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                       \u001b[0mFD_schemes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                       str(dn))\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mFD_schemes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dsirajud/Work/IPython-notebooks/Convergence of FD calculations of derivatives/pyfiles/../pyfiles/lib/make_FD_schemes_dict.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(infilename, FD_schemes, dn)\u001b[0m\n\u001b[0;32m     28\u001b[0m                 dn):\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0minfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: './etc/f1_LTE_3_FD_coefficients.dat'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from main import convergence_routine_single_scheme\n",
    "convergence_routine_single_scheme(NumGrids = 10, Nx = 18, LTE = 3, dn = 1, handedness = 'forward', asymmetry = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"order\" column reports the slope of the $L^2$ norms of the error between each mesh refinement, i.e.\n",
    "\n",
    "$$\\text{order}_i = \\log_2\\left(\\frac{||f_{\\Delta x} - f_{exact}||_{2}}{||f_{\\Delta x/2} - f_{exact}||_{2}}\\right)$$\n",
    "\n",
    "where $|| g(x) ||_2 := \\sqrt{ \\frac{1}{L}\\sum_i g(x_i)\\Delta x_i}$ as usual, equivalently we could have elected to track the history ofthe fractional deviation of the $L^2$ norm from one grid spacing to the next rather than the $L^2$ norm itself. It can be seen this stepthrough only differs by a constant and hence predicts equivalent convergence.\n",
    "\n",
    "In fact, the scripts above compute the infinity-norm as well, which give a larger error but which decreases with the same expected convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence of the combination application of FD schemes that sample only grid points within the domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using one scheme runs into a problem at the edge where the differencing scheme requires grid sampling outside the domain, also looping through the summation form above is expensive. We wish to apply FD schemes of a given LTE (1) more efficiently ($\\Rightarrow$ matrix formulation is desired), and (2) for nonperiodic functions ($\\Rightarrow$ one-sided schemes (varying handedness and degrees of asymmetry must be used near the edges of the domain). This assembly is clearly to set up a matrix multiplication of a weight matrix $W$ with a grid vector $x$ so that \n",
    "\n",
    "$$\\underline{\\underline{W}}_{N\\times N}\\underline{x}_{N\\times 1} = \\underline{df}_{N\\times 1}$$\n",
    "\n",
    "gives the derivative vector $df$. The construction of $W$ is straightforward, its top row corresponds to the left-edge of the domain (forward 0 difference), the bottom row applies to the right-edge (backward 0 difference), the nodes well inside the interior can use the most asymmetric scheme of a given handedness (either a forward/backward scheme of maximum asymmetry or a central scheme should one exist [i.e. for stencil sizes that are odd]). Thus, the assembly of $W$ is as follows where we take the example of $N$ grid points with indices $i = 0, 1, \\ldots , N-2, N-1$ for a derivative of order $dn$ of some chosen $LTE$ where the maximum degree of asymmetry is 2 (in general, the maximum asymmetry = [(LTE + dn) // 2 - 1] and the stencil is odd so that there exists a central scheme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\underbrace{\\left( \\begin{array}{c}\n",
    "\\text{forward 0} \\\\\n",
    "\\text{forward 1} \\\\\n",
    "\\text{forward 2} \\\\\n",
    "\\text{central 0} \\\\\n",
    "\\ldots \\\\\n",
    "\\text{central 0} \\\\\n",
    "\\text{central 0} \\\\\n",
    "\\text{central 0} \\\\\n",
    "\\ldots \\\\\n",
    "\\text{central 0} \\\\\n",
    "\\text{backward 2} \\\\\n",
    "\\text{backward 1} \\\\\n",
    "\\text{backward 0} \\end{array} \\right)}_{W_{N\\times N}}\n",
    "\\underbrace{\\left( \\begin{array}{c}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "\\ldots \\\\\n",
    "x_{N_{odd}/2 - 1} \\\\\n",
    "x_{N_{odd}/2} \\\\\n",
    "x_{N_{odd}/2 + 1} \\\\\n",
    "\\ldots \\\\\n",
    "x_{N-4} \\\\\n",
    "x_{N-3} \\\\\n",
    "x_{N-2} \\\\\n",
    "x_{N-1} \\end{array} \\right)}_{x_{N\\times 1}} \n",
    "= \n",
    "\\underbrace{\\left( \\begin{array}{c}\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_0)\\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_1) \\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_2) \\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_3) \\\\\n",
    "\\ldots \\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_{N_{odd}/2 - 1}) \\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_{N_{odd}/2}) \\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_{N_{odd}/2 + 1}) \\\\\n",
    "\\ldots \\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_{N-4}) \\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_{N-3}) \\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_{N-2}) \\\\\n",
    "\\frac{d^{dn}f}{dx^{dn}}(x_{N-1}) \\end{array} \\right)}_{df_{N\\times 1}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the event the stencil is even, there is no central scheme and instead the interior nodes are sampled with a differencing scheme in the generated tables that has maximum asymmetry (i.e. backward/forward schemes that are as centered as possible). corresponding to This setup is accomplished pyfiles/bin/main.FD_derivative_matrix_formulation by extracting the required schemes from a dictionary of dictionaries (of dictionaries of...) constructed in pyfiles/lib/make_FD_schemes_dict.store. We again consider $dn = 1$, $LTE= 3$, which reads a generated .dat table from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import generate_tables_of_finite_difference_schemes_for_a_given_LTE\n",
    "\n",
    "generate_tables_of_finite_difference_schemes_for_a_given_LTE.main(LTE = 3, dn = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which produces the table:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f^(1): LTE = O(z^3)\n",
    "=========================\n",
    "\n",
    "f^(1): forward 0\n",
    "-------------------------\n",
    "(weights, stencil)\n",
    "-1.83333,  0\n",
    "3.00000,  1\n",
    "-1.50000,  2\n",
    "0.33333,  3\n",
    "-------------------------\n",
    "f^(1): forward 1\n",
    "-------------------------\n",
    "(weights, stencil)\n",
    "-0.33333, -1\n",
    "-0.50000,  0\n",
    "1.00000,  1\n",
    "-0.16667,  2\n",
    "-------------------------\n",
    "f^(1): backward 1\n",
    "-------------------------\n",
    "(weights, stencil)\n",
    "0.16667, -2\n",
    "-1.00000, -1\n",
    "0.50000,  0\n",
    "0.33333,  1\n",
    "-------------------------\n",
    "f^(1): backward 0\n",
    "-------------------------\n",
    "(weights, stencil)\n",
    "-0.33333, -3\n",
    "1.50000, -2\n",
    "-3.00000, -1\n",
    "1.83333,  0\n",
    "-------------------------\n",
    "========================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example, consider a domain consisting of 6 grid point $x_0, x_1, \\ldots , x_5$. The weight matrix  $\\underline{\\underline{W}}$ would take the general form in the matrix equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\left(\\begin{array}{c}\n",
    "\\text{forward 0} \\\\\n",
    "\\text{forward 1} \\\\\n",
    "\\text{forward 1} \\\\\n",
    "\\text{forward 1} \\\\\n",
    "\\text{backward 1} \\\\\n",
    "\\text{backward 0}\n",
    "\\end{array} \\right)\n",
    "\\left( \\begin{array}{c}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4 \\\\\n",
    "x_5 \n",
    "\\end{array} \\right)\n",
    "= \\left(\\begin{array}{c}\n",
    "df(x_0)/dx \\\\\n",
    "df(x_1)/dx \\\\\n",
    "df(x_2)/dx \\\\\n",
    "df(x_3)/dx \\\\\n",
    "df(x_4)/dx \\\\\n",
    "df(x_5)/dx \n",
    "\\end{array} \\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the specific form, using the above table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\left(\\begin{array}{c c c c c c}\n",
    "-1.833 & \\phantom{-}3.000 & -1.500 & \\phantom{-}0.333 & 0 & 0 \\\\\n",
    "\\phantom{-}0.333 & -0.500 & \\phantom{-}1.000 & -0.167 & 0 & 0 \\\\\n",
    "0 & -0.333 & -0.500 & \\phantom{-}1.000 & -0.167 & 0 \\\\\n",
    "0 & 0 & -0.333 & -0.500 & \\phantom{-}1.000 & -0.166 \\\\\n",
    "0 & 0 & \\phantom{-}0.167 & -1.000 & 0.500 & 0.333 \\\\\n",
    "0 & 0 & -0.333 & \\phantom{-}1.500 & -3.000 & \\phantom{-}1.833\n",
    "\\end{array} \\right)\n",
    "\\left( \\begin{array}{c}\n",
    "x_0 \\\\\n",
    "x_1 \\\\\n",
    "x_2 \\\\\n",
    "x_3 \\\\\n",
    "x_4 \\\\\n",
    "x_5 \n",
    "\\end{array} \\right)\n",
    "= \\left(\\begin{array}{c}\n",
    "df(x_0)/dx \\\\\n",
    "df(x_1)/dx \\\\\n",
    "df(x_2)/dx \\\\\n",
    "df(x_3)/dx \\\\\n",
    "df(x_4)/dx \\\\\n",
    "df(x_5)/dx \n",
    "\\end{array} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "A convergence routine can be run for the same case: $dn = 1$, $LTE = 3$ which now only samples grid points in the domain (i.e. without periodicity). The convergence is demonstrated through the following routine. The matrix product can be accomplished efficiently in python as "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = W.dot(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, in NumPy, the multiplication operation * is a vectorizing component-wise product of elements, a matrix dot product must be employed as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from main import convergence_routine_nonperiodic\n",
    "convergence_routine_nonperiodic(NumGrids = 10, Nx = 18, LTE = 3, dn = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works smoothly for the first derivative, however for higher order derivatives we encounter optimal mesh spacings whereafter the derivatives begin to steadily (exponentially) increase with subsequent mesh refinement. First, to show that edge effects do not change the conclusion, we complete the grid sampling of the FD scheme using periodicity, and show the $L^2$ norm of the error continues to decrease as the mesh is refined but there exists an inflection point where the error steadily increases. We consider changes sign, we first show a central scheme for the $dn = 3$ and $LTE = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical error accumulation for $d^{n}f/dx^{n}$, $dn > 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "convergence_routine_single_scheme(NumGrids = 12, Nx = 48, LTE = 3, dn = 2, handedness = 'forward', asymmetry = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error decreases with at a convergence rate of $O(\\Delta x^3)$ as needed (see output table above) but for grids with total points $N_x > 6144$ ($\\Delta x := L / N_x$ less than $\\Delta x = (1 - (-1)) / 6144 = 0.000325520833$) an increase in error at $O(\\Delta x^2$). Thus, there exists an optimal range of of grid spacings $\\Delta x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now show this also occurs for the matrix formulation (which, again, uses a host of schemes to sample only grid points within the domain without using periodicity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from main import convergence_routine_nonperiodic\n",
    "L2_error_dn2_LTE3, grids_dn2_LTE3 = convergence_routine_nonperiodic(NumGrids = 9, Nx = 48, LTE = 3, dn = 2, plots = 'yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the inflection point remains around $N_x \\sim 2^{12}$ gives a range where the convergence is demonstrated. Note that the matrix formulation uses a central differencing scheme for interior nodes (producing $LTE = O(\\Delta x^{3+1})$ as usual) and the asymmetric forward/backward schemes have truncation error $O(\\Delta x^3)$. Thus, we anticipate the numerical convergnece to be between 3 ~ 4; this is sen to be true above (~ 3.5 for the range Nx64 ~ Nx512). The optimal grid size among the above is 512 grid points over $x\\in [-1,1]$, or $\\Delta x = L / N_x = (1 - (-1)) / 512 = 0.00390625$ per cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical error source terms, inflection points, and calculation of the rate of increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source of error increase at $N_x > 512$ is approximately of constant slope, indicating the LTE is contaminated by a term that becomes important for large $N_x$ ($\\Delta x$ small). Since this not analytically predicted in the standard derivations of these schemes, the error must be numerical and it must manifest as a term that scales with $O(\\Delta x^{-2})$ to produce the positive slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the form of this term, we consider for example the forward 0 scheme for $dn = 2$ at an $LTE = O(\\Delta x^3)$ (see plot above). We generate the required table for the associated scheme via "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pyfiles/bin/$ python generate_tables_of_finite_difference_schemes_for_a_given_LTE 3 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, paste the excerpt from the decorated output table below for our reference here:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f^(2): LTE = O(z^3)\n",
    "=========================\n",
    "\n",
    "f^(2): forward 0\n",
    "-------------------------\n",
    "(weights, stencil)\n",
    "2.91667,  0\n",
    "-8.66667,  1\n",
    "9.50000,  2\n",
    "-4.66667,  3\n",
    "0.91667,  4\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be verified these agree with those reported in literature. Note: the actual script uses precision up to 21 digits for the coefficients, these are abbreviated numbers formatted for readability. The above corresponds to (where we use $\\delta$ to denote finite differencing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{d^2f}{dx^2} - \\frac{\\delta^2 f}{\\delta x^2} = O(\\Delta x^3)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the stencil and weights above give (using rational representations):\n",
    "\n",
    "$$\\frac{\\delta^2 f(x_i)}{\\delta x^2} = \\frac{1}{(\\Delta x)^2}\\left[\\frac{35}{12}f(x_i) - \\frac{26}{3}f(x_{i+1}) + \\frac{19}{2}f(x_{i+2}) - \\frac{14}{3}f(x_{i+3}) + \\frac{11}{12}f(x_{i+4})\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose each function evaluation at a grid point $x_{i+j}$, ($j = \\{0, 1, 2, 3, 4\\}$) incurs with a machine error $\\epsilon_{i+j}$. The above theoretical differencing them takes the following form when considering the limitations of computation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray*}\n",
    "\\frac{\\delta^2 f(x_i)}{\\delta x^2} & = & \\frac{1}{(\\Delta x)^2}\\left[\\frac{35}{12}(f(x_i) + \\epsilon_i) - \\frac{26}{3}(f(x_{i+1})+ \\epsilon_{i+1}) + \\frac{19}{2}(f(x_{i+2}) + \\epsilon_{i+2}) - \\frac{14}{3}(f(x_{i+3}) + \\epsilon_{i+3}) + \\frac{11}{12}(f(x_{i+4}) + \\epsilon_{i+4})\\right] \\\\[0.5em]\n",
    "& = & \\frac{1}{(\\Delta x)^2}\\left[\\frac{35}{12}f(x_i) - \\frac{26}{3}f(x_{i+1}) + \\frac{19}{2}f(x_{i+2}) - \\frac{14}{3}f(x_{i+3}) + \\frac{11}{12}f(x_{i+4})\\right] + \\frac{1}{(\\Delta x)^2}\\left[\\frac{35}{12}\\epsilon_i - \\frac{26}{3}\\epsilon_{i+1} + \\frac{19}{2}\\epsilon_{i+2} - \\frac{14}{3}\\epsilon_{i+3} + \\frac{11}{12}\\epsilon_{i+4}\\right] \n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we have\n",
    "\n",
    "$$\\frac{d^2f}{dx^2} - \\frac{\\delta^2 f}{\\delta x^2} = O(\\Delta x^3) + \\frac{1}{(\\Delta x)^2}\\left[\\frac{35}{12}\\epsilon_i - \\frac{26}{3}\\epsilon_{i+1} + \\frac{19}{2}\\epsilon_{i+2} - \\frac{14}{3}\\epsilon_{i+3} + \\frac{11}{12}\\epsilon_{i+4}\\right]$$\n",
    "\n",
    "In general, it is not anticipated these machine errors (also of unpredictable sign) would cancel. Writing each error $\\epsilon_{i+j} = \\epsilon_{i+j}(\\epsilon )$ where $\\epsilon$ is the machine error, we report the above as proportional to an overall constant $\\tilde{M}$, so that\n",
    "\n",
    "\n",
    "$$\\frac{d^2f}{dx^2} - \\frac{\\delta^2 f}{\\delta x^2} = O(\\Delta x^3) + \\frac{\\tilde{M}}{(\\Delta x)^2}\\epsilon$$\n",
    "\n",
    "Thus, the increase in error increases with decreasing mesh spacing with order $O(\\Delta x^{-2})$ as observed in the plots above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the form of the $LTE = O(\\Delta x^3)$ was known (for this case, easily derivable), then the right-hand side could be optimized to find a minimum which would correspond to the infection \"point\" (the spacing $\\Delta x$ (equivalently, the grid described by the total grid points $N_x$) that is a global minimum in the $L^2$ norm of the error. This should agree with the plot above to be around  $\\sim Nx = 6144$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, deriving optimal mesh spacings for a particular derivative at the desired $LTE$ will be wasted effort if multiple derivatives are aimed to be used for an applicaiton (e.g. in high order CS, to correct the advection solver up to an $LTE = N+1$, derivatives of order $1, 2, \\ldots , N-1$ are needed) since each derivative will have a different optimal range for convergence. Rather than explore this analytically, we run a convergence routine on several derivatives at the same LTE and motivate some ideas to permit reasonable estimations for their inflection points in what follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juxtaposition of inflection points in the $L^2$ norm of the error for several derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate tables for the families of schemes for derivatives 1 <= dn <= 4, we use the looping script for LTE = 3, dn_min = 1, dn_max = 4 for the sys.argv inputs in the python script call then call the convergence routine that is so-named."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pyfiles/bin$ python generate_tables_of_finite_difference_schemes_for_a_given_LTE_for_range_of_derivatives.py 3 1 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from main import convergence_for_several_derivatives_at_const_LTE, convergence_routine_nonperiodic\n",
    "convergence_for_several_derivatives_at_const_LTE(NumGrids = 10, _LTE = 3, _dn_max = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We see the expected convergence to at least the LTE = 3 for each derivative. As before, if there exists a central scheme (i.e. odd stencil size = LTE + dn, for example LTE = 3, dn = 4) we expect convergence somewhere close to an order 3.5 since the central scheme cancels off an extra truncation term and is thus order 4 which is mixed with forward/backward schemes near the edges (order 3). The inflection points for each derivative are different. \n",
    "\n",
    "The plot on the bottom shows the convergence for all 4 derivatives only occurs in a range $21 < N_x < 336$ (equivalent to $0.0952380 > \\Delta x > 0.0059523$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there exist different optimal ranges where all derivatives converge, and so seeking an analytical estimate for each derivative of an upper bound on $N_x$ (or lower bound on $\\Delta x$) is not a worthwhile exercise. Instead, the range can be determined numerically and abided to in employing it in a larger application (e.g. in DECSKS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Investigation of regimes where numerical error dominates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the order as above:\n",
    "\n",
    "$$\\text{order}_i = \\log_2\\frac{||E_{\\Delta x}||_2}{||E_{\\Delta x/2}}$$\n",
    "\n",
    "where $E_{\\Delta x} = f_{exact} - f_{\\Delta x}$\n",
    "\n",
    "The truncation error is bounded by constants $C_{\\Delta x}, C_{\\Delta x / 2}, M_{\\Delta x}, M_{\\Delta x/2}$, which depend on the mesh spacing, where $C$ limits the size on the LTE and $M$ is associated with the aforementioned numerical source of error (and thus also depends on the machine error $\\sim 10^{-16}$. Writing the order of the LTE as $p$, and the derivative order of interest as $n$ (also the negative order with which the machine error scales with). Thus, the above is written as\n",
    "\n",
    "$$\\text{order}_i = \\log_2\\frac{C_{\\Delta x}(\\Delta x)^{p} + M_{\\Delta x}(\\Delta x)^{-n}}{C_{\\Delta x / 2}(\\Delta x / 2)^{p} + M_{\\Delta x / 2}(\\Delta x / 2)^{-n}}$$\n",
    "\n",
    "Formally, we can choose to retain the constants as distinct. The result does not change if we exploit how large the difference there is in order of magnitude between the two sets of constants, i.e. the result does not change if we chose the constants $C_{\\Delta x} = C_{\\Delta x/2} \\sim 1$ and $M_{\\Delta x} = M_{\\Delta x / 2} \\sim \\tilde{M}\\epsilon \\sim \\epsilon$ where $\\epsilon$ is machine epsilon and $\\tilde{M}$ was a multiplicative constant mentioned in a previous section. This also permits a cleaner equation work which is easier to follow and gets to the point more expediently.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\text{order}_i & = &  \\log_2\\frac{(\\Delta x)^{p} + \\epsilon (\\Delta x)^{-n}}{(\\Delta x / 2)^{p} + \\epsilon (\\Delta x / 2)^{-n}} \\\\[1em]\n",
    "& = & \\log_2 \\left\\{ 2^n \\frac{\\epsilon^{-1}(\\Delta x)^{n + p} + 1}{\\epsilon^{-1}(2\\Delta x)^{n + p} + 1}\\right\\} \\\\[1em]\n",
    "& = & \\log_2 2^n + \\log_2 \\left\\{\\frac{ \\epsilon^{-1}(\\Delta x)^{n + p} + 1}{(\\epsilon^{-1}2\\Delta x)^{n + p} + 1}\\right\\} \\\\[1em]\n",
    "\\text{order}_i & = & n + \\log_2 \\left\\{\\frac{ \\epsilon^{-1}(\\Delta x)^{n + p} + 1}{ \\epsilon^{-1}(2\\Delta x)^{n + p} + 1}\\right\\} \n",
    "\\end{eqnarray*}\n",
    "\n",
    "We consider the case for progressively smaller $\\Delta x$, and consider a regime where the numerical error accumulation, $\\epsilon (\\Delta x)^{-n}$ is sufficiently larger than the LTE term $(\\Delta x)^p$, i.e $\\epsilon (\\Delta x)^{-n} \\gg (\\Delta x)^p \\, \\Rightarrow \\, \\epsilon^{-1}(\\Delta x)^{n+p} \\ll 1$. Thus, the term in the denominator $\\epsilon^{-1}(2\\Delta x)^{n + p} \\ll 1$ permits an expansion in this small parameter.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\text{order}_i  & = & n + \\log_2 \\left\\{(1 + \\epsilon^{-1}(\\Delta x)^{n + p})(1 - \\epsilon^{-1}(2\\Delta x)^{n+p} + \\epsilon^{-2}(2\\Delta x)^{2(n + p)} + \\ldots)\\right\\} \\\\[1em]\n",
    " & = & n + \\log_2 (1 + \\epsilon^{-1}(\\Delta x)^{n + p}) + \\log_2 (1 - \\epsilon^{-1}(2\\Delta x)^{n+p} + \\epsilon^{-2}(2\\Delta x)^{2(n + p)} + \\ldots )\\\\[1em]\n",
    "\\text{order}_i  & = & n + \\log_2 (1 + \\epsilon^{-1}(\\Delta x)^{n + p}) + \\log_2 (1 - \\epsilon^{-1}(2\\Delta x)^{n+p}), \\qquad \\textrm{since } \\epsilon^{-1}(2\\Delta x)^{2(n+p)} \\ll \\epsilon^{-1}(2\\Delta x)^{n+p}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Expanding the logarithms\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\text{order}_i  & = & n + (\\epsilon^{-1}(\\Delta x)^{n + p}) - \\epsilon^{-2}(\\Delta x)^{2(n + p)}) + \\ldots) + (-\\epsilon^{-1}(2\\Delta x)^{n+p} - \\epsilon^{-2}(2\\Delta x)^{2(n+p)} + \\ldots) \n",
    "\\end{eqnarray*}\n",
    "\n",
    "Hence, in the limit of $\\Delta x \\rightarrow 0$ where the machine error dominates $\\epsilon (\\Delta x)^{-n} \\gg (\\Delta x)^p \\Rightarrow \\epsilon^{-1}(\\Delta x)^{n+p} \\ll 1$, we recover a positive slope which corresponds to the order of the derivative $n$\n",
    "\n",
    "\n",
    "$$\\boxed{\\lim_{\\Delta x \\rightarrow 0} \\text{order}_i = n}, \\quad \\textrm{when } \\epsilon (\\Delta x)^{-n} \\gg (\\Delta x)^p$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critical spacing $(\\Delta x)_{crit}$ that marks the inflection point (i.e. the point upon which subsequent mesh refinement is dominated by an increasing numerical error) can then be estimated by considering the equality\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\epsilon(\\Delta x)_{crit}^{-n} & = & (\\Delta x)^p_{crit} \\\\[1em]\n",
    "\\epsilon & = & (\\Delta x)^{n + p}_{crit}  \\\\[1em]\n",
    "\\log \\epsilon & = & (n + p)\\log (\\Delta x)_{crit} \\\\[1em]\n",
    "\\frac{\\log \\epsilon }{n + p} & = & \\log (\\Delta x)_{crit} \\\\[1em]\n",
    "\\Rightarrow (\\Delta x)_{crit} & = & \\exp\\left[ \\frac{\\log \\epsilon }{n + p} \\right] \\\\[1em]\n",
    " & = & \\exp\\left[\\log \\epsilon^{1/ (n + p)}\\right] \\\\[1em]\n",
    "  & = & \\exp\\left[\\log \\epsilon^{(n + p)^{-1}}\\right] \\\\[1em]\n",
    "\\Rightarrow (\\Delta x)_{crit} & = & \\epsilon^{(n + p)^{-1}}\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Writing $(\\Delta x)_{crit} = L / N_{x,crit}$ So we see that,\n",
    "\n",
    "\\begin{eqnarray*}\n",
    " (\\Delta x)_{crit} := \\frac{L}{N_{x,crit}} & = & \\epsilon^{(n + p)^{-1}} \\\\[1em]\n",
    "\\frac{N_{x,crit}}{L} & = & \\frac{1}{\\epsilon^{(n + p)^{-1}}} \\\\[1em]\n",
    "N_{x,crit} & = & \\frac{L}{\\epsilon^{(n + p)^{-1}}} \\\\[1em]\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the cases plotted above, we have $LTE \\equiv p = 3$, $dn \\equiv n = 2$, thus the rough estimate of the number of grid points $N_{x,crit}$ needed in a mesh for the numerical error begins to dominate is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "eps = np.finfo(float).eps\n",
    "p, n = 3, 2\n",
    "L = 2.\n",
    "\n",
    "N_xcrit = L  / eps ** (1 / float(n + p))\n",
    "print \"N_x > %g grid points ~ 2^(%2.1f) grid points is the turning point where numerical error dominates\" % (N_xcrit, np.log2(N_xcrit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this with the plots above and the output data tables, which show an inflection point around $N_x \\sim 3072$ ($\\Delta x = 0.000651041\\bar{6}$), this estimate of $N_x \\sim 2702$ ($\\Delta x = 0.0007401924500370096$) agrees satisfactorily (within $\\sim 12\\%$). In particular, using the same meshes in the refinement exercise above, we can compare the LTE error $(\\Delta x)^p$ with the numerical error $\\epsilon (\\Delta x)^{-n}$ to see when the changeover in dominating term occurs, and we also plot a scaled L2 error (to fit it on the same plot window) to show these coarse predictions match up quite well with the actual inflection of the L2 errors in the finite difference calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "eps = np.finfo(float).eps # machine epsilon\n",
    "\n",
    "\n",
    "L = 2.\n",
    "NumGrids = 12\n",
    "Nx, LTE, num_error = np.zeros(NumGrids), np.zeros(NumGrids), np.zeros(NumGrids)\n",
    "for i in range(12):\n",
    "    Nx[i] = 48 * 2 ** i\n",
    "    dx = L / Nx[i]\n",
    "    \n",
    "    LTE[i] = dx ** 3\n",
    "    num_error[i] = eps * dx ** (-2)\n",
    "    \n",
    "    print \"Nx\", 48 * 2 **i, \"LTE term = %g\" % dx ** 3, \"numerical error term = %g\" % (eps*dx ** (-2))\n",
    "   \n",
    "fig, ax = plt.subplots()\n",
    "ax.loglog(Nx,LTE, '--o', label = '$LTE$')\n",
    "ax.hold('on')\n",
    "ax.loglog(Nx, num_error, '--D', label = 'Numerical error')\n",
    "ax.loglog(grids_dn2_LTE3, L2_error_dn2_LTE3 * 2 ** (-18) / np.max(L2_error_dn2_LTE3), '--o', label = 'Normalized $L^2$ error from FD calc')\n",
    "ax.set_xscale('log', basex = 2)\n",
    "ax.set_yscale('log', basey = 2)\n",
    "\n",
    "plt.xlabel(r'Number of grid points $N_x$ over $x\\in [-1,1]$', fontsize = 16)\n",
    "plt.ylabel('Errors', fontsize = 16)\n",
    "\n",
    "frame = ax.get_position() # position of plot center\n",
    "\n",
    "# shrink frame of the plot to make room for a legend on the right side\n",
    "ax.set_position([frame.x0, frame.y0, \n",
    "                 frame.width * 0.8, frame.height])\n",
    "\n",
    "# Place legend to the right of the shrunken frame\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "          fancybox=True, ncol=1)\n",
    "\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see by inspection that the <font color = \"red\">red</font> curve representing the $L^2$ error agrees with the errors (LTE and numerical error). The drop rate of the L2 error is seen to decrease at a rate a bit steeper than the modelled $LTE = \\Delta x^3$, as discussed previously (the central scheme is has $LTE = O(\\Delta x^4)$ so we acheive a bit higher accuracy, $\\sim 3.5$). After the inflection, where the error begins to increase we see it matches very identically to the numerical error slope, which is of order $O(\\Delta x^{-2})$ for this second order derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A class of explicit finite difference formulations for any order derivative of any chosen local truncation error (LTE) has been devised and implemented. The family of explicit schemes of varying handedness and degrees of asymmetry in their grid sampling are stacked inside a NumPy array so that array multiplication with the grid function whose derivative is desired permits direct and efficient calculation of the required valuesfor all grid points without relying on sampling grid points outside the domain as would pervade any finite difference calculation using a single scheme.\n",
    "\n",
    "The convergence of the derivatives is guaranteed to be at least the selected LTE, though the overall numerical order of convergence can be a bit higher should there exist a central scheme in the family of generated finite difference coefficients (i.e. a central schemes on uniform grids have the benefit of a fortuitous cancellation of an extra term in the LTE which raises their convergence rate by one order), which is applied to most of the domain (i.e. the interior nodes).\n",
    "\n",
    "In the pursuit of mesh refinement, we noticed higher order derivatives showed inferior calculation as compared with coarser grids. Since there is no analytical means by which this would occur, it was posited that a numerical source of error that scales with the inverse power that is the same order of the derivative must exist. This was included in a simple analytical workup, and a coarse estimate was developed. By examining these coarse estimates of the errors (LTE vs. numerical error buildup), we saw the inflection point where the L2 error in the FD calculation of a derivative begins to increase with finer meshes rather than decrease agreed within 12% for the test case of $\\delta^2 f / \\delta x^2$ ($LTE = O(\\Delta x^3 )$. A final plot showing these errors as well as a scaled L2 error of the FD calculations show a satisfying picture that the L2 error containing a turning point in the vicinity as that predicted by our coarse estimates."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
